{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting credit default with XGBoost\n",
    "_**Supervised Learning with Gradient Boosted Trees: A Binary Prediction Problem **_\n",
    "\n",
    "_NOTE: This notebook was created and tested using the `Python 3 (Data Science)` kernel._\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Background](#Background)\n",
    "1. [Preparation](#Preparation)\n",
    "1. [Data](#Data)\n",
    "    1. [Exploration](#Exploration)\n",
    "    1. [Transformation](#Transformation)\n",
    "1. [Training](#Training)\n",
    "1. [Hosting](#Hosting)\n",
    "1. [Evaluation](#Evaluation)\n",
    "1. [Extensions](#Extensions)\n",
    "\n",
    "---\n",
    "\n",
    "## Background\n",
    "\n",
    "We will be using a dataset from the UCI Machine Learning Repository\n",
    "\n",
    "This dataset contains information on default payments, demographic factors, credit data, history of payment, and bill statements of credit card clients in Taiwan from April 2005 to September 2005.\n",
    "\n",
    "The original dataset can be found here at the UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install additional libraries\n",
    "\n",
    "[Pandas profiling](https://github.com/pandas-profiling/pandas-profiling) works great for smaller datasets. Pandas profiling does not come preinstalled on the Data Science Kernel, but we can install it with pip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas-profiling[notebook] --quiet\n",
    "!pip install sagemaker-experiments --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "Let's start by specifying:\n",
    "\n",
    "- The S3 bucket and prefix that you want to use for training and model data.  This should be within the same region as the Notebook Instance, training, and hosting.\n",
    "- The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these.  Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the boto regexp with a the appropriate full IAM role arn string(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "isConfigCell": true,
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import re\n",
    "import sagemaker # Amazon SageMaker's Python SDK provides many helper functions\n",
    "\n",
    "session = sagemaker.Session()\n",
    "\n",
    "bucket = session.default_bucket()\n",
    "prefix = 'sagemaker/credit-xgboost'\n",
    " \n",
    "# Define IAM role\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(bucket,prefix,role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's bring in the Python libraries that we'll use throughout the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                                # For matrix operations and numerical processing\n",
    "import pandas as pd                               # For munging tabular data\n",
    "import matplotlib.pyplot as plt                   # For charts and visualizations\n",
    "from IPython.display import Image                 # For displaying images in the notebook\n",
    "from IPython.display import display               # For displaying outputs in the notebook\n",
    "from time import gmtime, strftime                 # For labeling SageMaker models, endpoints, etc.\n",
    "import sys                                        # For writing outputs to notebook\n",
    "import math                                       # For ceiling function\n",
    "import json                                       # For parsing hosting outputs\n",
    "import os                                         # For manipulating filepath names\n",
    "import sagemaker.deserializers                    # Converts strings for HTTP POST requests on inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Data\n",
    "\n",
    "The dataset should already be available in the repository under the dataset folder. Now lets read this into a Pandas data frame and take a look.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./dataset/UCI_Credit_Card.csv')\n",
    "pd.set_option('display.max_columns', 500)     # Make sure we can see all of the columns\n",
    "pd.set_option('display.max_rows', 20)         # Keep the output on one page\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's talk about the data.  At a high level, we can see:\n",
    "\n",
    "* We have 30000 user and their credits records\n",
    "* 25 features per record\n",
    "* The features are numeric\n",
    "* The data is not sorted\n",
    "\n",
    "_**Specifics on each of the features:**_\n",
    "\n",
    "*Features:*\n",
    "* `ID`: ID of user\n",
    "* `LIMIT_BAL`: Amount of given credit in NT dollars (includes individual and family/supplementary credit\n",
    "* `SEX`: Gender (1=male, 2=female)\n",
    "* `EDUCATION`: (1=graduate school, 2=university, 3=high school, 4=others, 5=unknown, 6=unknown)\n",
    "* `Marriage`: Marital status (1=married, 2=single, 3=other)\n",
    "* `AGE`: Age in years\n",
    "* `PAY_0`: Repayment status for this month. (-2=No consumption, -1=paid duly, 0=use of revolving credit, 1=payment delayed 1 month, 2=payment delayed 2 months, [...], 9=payment delayed 9 months or more)\n",
    "* `PAY_2`: Repayment status for last month. (same as above)\n",
    "* `PAY_3`: Repayment status for 2 months ago. (same as above)\n",
    "* `PAY_4`: Repayment status for 3 months ago. (same as above)\n",
    "* `PAY_5`: Repayment status for 4 months ago. (same as above)\n",
    "* `PAY_6`: Repayment status for 5 months ago. (same as above)\n",
    "* `BILL_AMT1`: Amount of bill this month.\n",
    "* `BILL_AMT2`: Amount of bill last month.\n",
    "* `BILL_AMT3`: Amount of bill 2 months ago.\n",
    "* `BILL_AMT4`: Amount of bill 3 months ago.\n",
    "* `BILL_AMT5`: Amount of bill 4 months ago.\n",
    "* `BILL_AMT6`: Amount of bill 5 months ago.\n",
    "* `PAY_AMT1`: Amount of payment made this month.\n",
    "* `PAY_AMT2`: Amount of payment made last month.\n",
    "* `PAY_AMT3`: Amount of payment made 2 months ago.\n",
    "* `PAY_AMT4`: Amount of payment made 3 months ago.\n",
    "* `PAY_AMT5`: Amount of payment made 4 months ago.\n",
    "* `PAY_AMT6`: Amount of payment made 5 months ago.\n",
    "\n",
    "*Target variable:*\n",
    "* `default.payment.next.month`: Default payment next month (1=yes, 0=no).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration\n",
    "Let's start exploring the data.  First, let's understand how the features are distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "profile_data = data\n",
    "profile = ProfileReport(profile_data, title=\"Credit card default data set report\", minimal=True)\n",
    "profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Training (Local)\n",
    "\n",
    "Let's first train a simple decision tree model on our data. Our target variable is 'default.payment.next.month'. We will start with a tree depth of 10. We split our data into a training dataset consisting of 80% of the samples, and a test dataset with 20% of the samples. We also drop the ID column as it's a simple record identifier with no predictive value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, average_precision_score, roc_auc_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(['ID','default.payment.next.month'], axis=1), data.filter(like='default.payment.next.month'), test_size=0.20, random_state=42)\n",
    "\n",
    "classifier = DecisionTreeClassifier(max_depth=10, random_state=14) \n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "predictions_test = classifier.predict(X_test)\n",
    "predictions_test_prob = classifier.predict_proba(X_test)\n",
    "\n",
    "precision = precision_score(y_test, predictions_test)\n",
    "recall = recall_score(y_test, predictions_test)\n",
    "accuracy = accuracy_score(y_true = y_test, y_pred = predictions_test)\n",
    "f1 = f1_score(y_true = y_test, y_pred = predictions_test)\n",
    "auc_score = roc_auc_score(y_test, predictions_test_prob[:,1])\n",
    "\n",
    "print('Precision (tp / (tp + fp)): ', np.round(precision, 3))\n",
    "print('Recall (tp/(tp + fn))): ', np.round(recall, 3))\n",
    "print('Accuracy: ', np.round(accuracy, 3))\n",
    "print('F1 score: ', np.round(f1, 3))\n",
    "print('AUC score: ', np.round(auc_score, 3))\n",
    "\n",
    "print('\\nConfusion matrix for 0.5:')\n",
    "pd.crosstab(index=y_test.iloc[:,0].values, columns=predictions_test, rownames=['defaulted on payment'], colnames=['predicted value']) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we have good accuracy, our F1 score is quite low, due to the imbalance in classes - there are many more cases of not defaulting on payment so the model is biased. We have also more false negatives compared to false positives, and as such our precision is better than our recall for this model at a decision boundary of 0.5 probability.\n",
    "\n",
    "For binary classification, scikit-learn will by default make the assumption that 1 is the positive class (in this case the target 'thing' we are predicting, which is defaulting on credit), and 0 is the negative class. Our average precision is shown above to be around 36% - which is the amount of true positives among all inferred positives at different probabilistic decision thresholds 0 < thresh < 1. Precision is a good measure to determine, when the costs of False Positive is high.\n",
    "\n",
    "We can also see that the accuracy (how many of the total samples were correctly predicted) with our test dataset is around 81% and with our train dataset is around 84% meaning we are not overfitting to the training data.\n",
    "\n",
    "What would happen if we would use a tree depth of 100?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier(max_depth=100, random_state=14) \n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# test data set accuracy\n",
    "predictions = classifier.predict(X_test)\n",
    "print(\"Test set accuracy: {}\".format(accuracy_score(y_true = y_test, y_pred = predictions)))\n",
    "\n",
    "# train data set accuracy (to measure overfitting)\n",
    "predictions = classifier.predict(X_train)\n",
    "print(\"Train set accuracy: {}\".format(accuracy_score(y_true = y_train, y_pred = predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly now there is overfitting to the training data going on, with our model giving much better results on the data with which we trained than with data not seen before (test data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Feature Engineering\n",
    "\n",
    "Let's try to do some feature engineering and improve on the previous model accuracy.\n",
    "\n",
    "**Drop meaningless features**\n",
    "\n",
    "ID is used as a record identified and is not useful from a model training or prediction point of view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['ID'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Education of type 5, 6, and 0 are unknown, so let's combine them into 4 ('Others')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Education 5,6,and 0 are unknown, so set to 4 'Others'\n",
    "print(\"Before:\")\n",
    "print(data.EDUCATION.value_counts())\n",
    "print()\n",
    "\n",
    "data.loc[data['EDUCATION'] > 3 , 'EDUCATION'] = 4\n",
    "data.loc[data['EDUCATION'] == 0 , 'EDUCATION'] = 4\n",
    "\n",
    "print(\"After:\")\n",
    "print(data.EDUCATION.value_counts())\n",
    "print()\n",
    "\n",
    "# The same for Marriage, unknown value 0 can be set to 3 'Others'\n",
    "print(\"Before:\")\n",
    "print(data.MARRIAGE.value_counts())\n",
    "print()\n",
    "\n",
    "data.loc[data['MARRIAGE'] == 0 , 'MARRIAGE'] = 3\n",
    "\n",
    "print(\"After:\")\n",
    "print(data.MARRIAGE.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMax scaler to numerical features\n",
    "Scale the numerical features using a MinMax scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "columns_to_scale = ['AGE', 'LIMIT_BAL', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']\n",
    "\n",
    "data[columns_to_scale] = min_max_scaler.fit_transform(data[columns_to_scale])\n",
    "\n",
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-hot encode categorical values\n",
    "\n",
    "The Sex, Education and Marriage features are categorical with no inherent meaning to the ordering, which is why we one-hot encode them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_onehot_encode = ['SEX', 'EDUCATION', 'MARRIAGE']\n",
    "\n",
    "model_data = pd.get_dummies(data, prefix=columns_to_onehot_encode, columns=columns_to_onehot_encode)\n",
    "\n",
    "model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Move target column to front. \n",
    "SageMaker assumes first column is the target column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = model_data[ ['default.payment.next.month'] + [ col for col in model_data.columns if col != 'default.payment.next.month' ] ]\n",
    "\n",
    "model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validation_data, test_data = np.split(model_data.sample(frac=1, random_state=1729), [int(0.7 * len(model_data)), int(0.9 * len(model_data))])   # Randomly sort the data then split out first 70%, second 20%, and last 10% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload train and validation data to S3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv('train.csv', index=False, header=False)\n",
    "validation_data.to_csv('validation.csv', index=False, header=False)\n",
    "\n",
    "# Upload the dataset to our S3 bucket\n",
    "train_uri = session.upload_data(path='train.csv', key_prefix=prefix+'/train')\n",
    "validation_uri = session.upload_data(path='validation.csv', key_prefix=prefix+'/validation')\n",
    "\n",
    "print(train_uri)\n",
    "print(validation_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker Processing Jobs\n",
    "\n",
    "We did the previous data preparation steps on our notebook - for larger scale handling of data, we could use SageMaker Processing and Processing jobs to do the data preparation / feature engineering using a managed cluster. In our case, we used Scikit Learn, and SageMaker Processing supports it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=\"0.20.0\",\n",
    "    role=role,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=1,\n",
    ")\n",
    "\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "# We now upload the raw dataset\n",
    "cc_data_uri = session.upload_data(path='dataset/UCI_Credit_Card.csv', key_prefix=prefix+'/data')\n",
    "print(cc_data_uri)\n",
    "\n",
    "sklearn_processor.run(\n",
    "    code=\"./preprocessing.py\",\n",
    "    inputs=[\n",
    "        ProcessingInput(source=cc_data_uri, destination=\"/opt/ml/processing/input\"),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train_data\", source=\"/opt/ml/processing/output\", destination=\"s3://{}/{}/processed\".format(bucket, prefix))\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessing_job_description = sklearn_processor.jobs[-1].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our engineered data on S3, and we can download to compare with the same data we created in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.download_data(\"processing\", bucket, key_prefix=\"{}/processed\".format(prefix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker Training Jobs\n",
    "\n",
    "We will now train on our data using the SageMaker XGBoost Algorithm.\n",
    "\n",
    "First, we fetch the xgboost container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = sagemaker.image_uris.retrieve('xgboost', boto3.Session().region_name, version='latest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create input channels\n",
    "SageMaker work with the concept of channels. Here, we create a training and validation input channles to be used when training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data='s3://{}/{}/train'.format(bucket, prefix), content_type='csv')\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(s3_data='s3://{}/{}/validation'.format(bucket, prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Train the model\n",
    "To train the model, we\n",
    "* initiate a SageMaker session,\n",
    "* create an estimator object and specify training configuration,\n",
    "* set the hyperparameters,\n",
    "* call the fit method, passing in the training and validation channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    role, \n",
    "                                    instance_count=1, \n",
    "                                    instance_type='ml.m4.xlarge',\n",
    "                                    use_spot_instances=True,\n",
    "                                    max_run=3600,\n",
    "                                    max_wait=3600,\n",
    "                                    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "                                    sagemaker_session=sess)\n",
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        silent=0,\n",
    "                        objective='binary:logistic',\n",
    "                        num_round=25)\n",
    "\n",
    "xgb.fit({'train': s3_input_train, 'validation': s3_input_validation}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor = xgb.deploy(initial_instance_count=1,\n",
    "                           instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify how to serialize incoming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.serializer = sagemaker.serializers.CSVSerializer() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throw some test data at the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, rows=500):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = ''\n",
    "    for array in split_array:\n",
    "        predictions = ','.join([predictions, xgb_predictor.predict(array).decode('utf-8')])\n",
    "\n",
    "    return np.fromstring(predictions[1:], sep=',')\n",
    "\n",
    "predictions = predict(test_data.drop(['default.payment.next.month'], axis=1).to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute some metrics to evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score, accuracy_score, f1_score\n",
    "\n",
    "y_true = test_data['default.payment.next.month']\n",
    "\n",
    "average_precision = average_precision_score(y_true, np.round(predictions))\n",
    "accuracy = accuracy_score(y_true, np.round(predictions))\n",
    "f1 = f1_score(y_true = y_true, y_pred = np.round(predictions))\n",
    "\n",
    "print('Precision: ', np.round(average_precision, 3))\n",
    "print('Accuracy: ', np.round(accuracy, 3))\n",
    "print('F1 score: ', np.round(f1, 3))\n",
    "\n",
    "\n",
    "print('\\nConfusion matrix:')\n",
    "pd.crosstab(index=test_data['default.payment.next.month'], columns=np.round(predictions), rownames=['defaulted on payment'], colnames=['predictions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create ROC graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr, tpr, _ = roc_curve(test_data['default.payment.next.month'], predictions)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean up!\n",
    "When you're done, don't forget to tear down the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameter tuning\n",
    "There are many ways to tune the model hyper parameters. One way is to use SageMaker Automatic Hyperparameter Tuning.\n",
    "\n",
    "With Automatic Hyperparameter Tuning, we create a HyperparameterTuner and pass in the estimator we created before, define ranges for the parameters we want to tune, define which metric to optimise for and add some training configuration.\n",
    "\n",
    "We then call the fit method and pass in the training and validation channels.\n",
    "\n",
    "Once the tuning is complete, we deploy the tuner and the model with the best result in the tuning phase will automatically be chosen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import HyperparameterTuner, ContinuousParameter, IntegerParameter\n",
    "\n",
    "# Configure HyperparameterTuner\n",
    "my_tuner = HyperparameterTuner(estimator=xgb,  # previously-configured Estimator object\n",
    "                               objective_metric_name='validation:auc',\n",
    "                               hyperparameter_ranges={\n",
    "                                   'eta': ContinuousParameter(0, 0.5), \n",
    "                                   \"alpha\": ContinuousParameter(0, 1000), \n",
    "                                   \"min_child_weight\": ContinuousParameter(1, 120), \n",
    "                                   \"max_depth\": IntegerParameter(1, 10),\n",
    "                                   \"num_round\": IntegerParameter(1, 2000),\n",
    "                                   \"subsample\": ContinuousParameter(0.5, 1)\n",
    "                               },\n",
    "                               max_jobs=10,\n",
    "                               max_parallel_jobs=10)\n",
    "\n",
    "# Start hyperparameter tuning job\n",
    "my_tuner.fit({'train': s3_input_train, 'validation': s3_input_validation})\n",
    "\n",
    "# Deploy best model\n",
    "print('Deploying the model ')\n",
    "my_predictor = my_tuner.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move all our training jobs into a SageMaker *Experiment* so we can track their performance and rank them visually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smexperiments.experiment import Experiment\n",
    "import botocore.exceptions\n",
    "import uuid\n",
    "\n",
    "sm = boto3.Session().client('sagemaker')\n",
    "trial_name = 'hyper-parameter-tuning'\n",
    "\n",
    "# Let's create an Experiment with a name - Credit-default for example\n",
    "try:\n",
    "    my_experiment = Experiment.create(experiment_name='credit-default')\n",
    "except botocore.exceptions.ClientError as e:\n",
    "    print(\"Experiment already created...\")\n",
    "    pass\n",
    "# And a trial within that Experiment\n",
    "try:\n",
    "    my_trial = my_experiment.create_trial(trial_name=trial_name)\n",
    "except botocore.exceptions.ClientError:\n",
    "    print(\"Trial already created...\")\n",
    "    pass\n",
    "\n",
    "# Now let's move our training jobs into the trial, as trial components.\n",
    "for trial_component in sm.list_trial_components(MaxResults=100)['TrialComponentSummaries']:\n",
    "    if trial_component['TrialComponentSource']['SourceType'] == 'SageMakerTrainingJob':\n",
    "        sm.associate_trial_component(TrialComponentName=trial_component['TrialComponentName'], TrialName=trial_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the SageMaker Studio 'Components and registries' on the sidebar, if you select 'Experiments and trials' and then navigate to the Experiment and Trial we just created, you can then select the multiple trial components (our hpt training jobs), sort them, deploy a model from the most suitable one, and create charts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test new model\n",
    "As before, we inform the predictor how to serialize the incoming data, then we run a set of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_predictor.serializer = sagemaker.serializers.CSVSerializer() \n",
    "\n",
    "# Make a prediction against the SageMaker endpoint\n",
    "def predict(data, rows=500):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = ''\n",
    "    for array in split_array:\n",
    "        predictions = ','.join([predictions, my_predictor.predict(array).decode('utf-8')])\n",
    "\n",
    "    return np.fromstring(predictions[1:], sep=',')\n",
    "\n",
    "predictions = predict(test_data.drop(['default.payment.next.month'], axis=1).to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model evaluation\n",
    "Let's evaluate the performance of the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test_data['default.payment.next.month']\n",
    "\n",
    "average_precision = average_precision_score(y_true, np.round(predictions))\n",
    "accuracy = accuracy_score(y_true, np.round(predictions))\n",
    "f1 = f1_score(y_true = y_true, y_pred = np.round(predictions))\n",
    "\n",
    "print('Precision: ', np.round(average_precision, 3))\n",
    "print('Accuracy: ', np.round(accuracy, 3))\n",
    "print('F1 score: ', np.round(f1, 3))\n",
    "\n",
    "\n",
    "print('\\nConfusion matrix:')\n",
    "pd.crosstab(index=test_data['default.payment.next.month'], columns=np.round(predictions), rownames=['defaulted on payment'], colnames=['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr, tpr, _ = roc_curve(test_data['default.payment.next.month'], predictions)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean up!\n",
    "When you're done, don't forget to tear down the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-central-1:936697816551:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
